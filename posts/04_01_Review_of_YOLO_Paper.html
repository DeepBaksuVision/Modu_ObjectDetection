
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>01). You Only Look Once 논문리뷰 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="04_02_Model.html" />
    
    
    <link rel="prev" href="04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    모두를 위한 Object Detection(Object Detection for All)
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="00_00_preface.html">
            
                <a href="00_00_preface.html">
            
                    
                    00. preface
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1.1" data-path="00_01_Author.html">
            
                <a href="00_01_Author.html">
            
                    
                    01). Author
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.1.2" data-path="00_02_Revision.html">
            
                <a href="00_02_Revision.html">
            
                    
                    02). Revision
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.1.3" data-path="00_03_Table_of_contents.html">
            
                <a href="00_03_Table_of_contents.html">
            
                    
                    03). Table of contents
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="01_00_What_is_Object_Detection.html">
            
                <a href="01_00_What_is_Object_Detection.html">
            
                    
                    01. Object Detection 이란?
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="02_00_Datasets_for_Object_Detection.html">
            
                <a href="02_00_Datasets_for_Object_Detection.html">
            
                    
                    02. Datasets for Object Detection
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.3.1" data-path="02_01_PASCAL_VOC.html">
            
                <a href="02_01_PASCAL_VOC.html">
            
                    
                    01). PASCAL VOC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3.2" data-path="02_02_Convert2Yolo.html">
            
                <a href="02_02_Convert2Yolo.html">
            
                    
                    02). Convert2Yolo 소개
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="03_00_common_utils.html">
            
                <a href="03_00_common_utils.html">
            
                    
                    03. Common Utils
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.4.1" data-path="03_01_dataloader.html">
            
                <a href="03_01_dataloader.html">
            
                    
                    01). DataLoader
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4.2" data-path="03_04_augmentation.html">
            
                <a href="03_04_augmentation.html">
            
                    
                    02). Augmentation
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4.3" data-path="03_05_visdom.html">
            
                <a href="03_05_visdom.html">
            
                    
                    03). Visdom
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4.4" data-path="03_04_torchsummary.html">
            
                <a href="03_04_torchsummary.html">
            
                    
                    04). Torch summary
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.html">
            
                <a href="04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.html">
            
                    
                    04. You Only Look Once: Unified, Real-Time Object Detection
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter active" data-level="1.1.5.1" data-path="04_01_Review_of_YOLO_Paper.html">
            
                <a href="04_01_Review_of_YOLO_Paper.html">
            
                    
                    01). You Only Look Once 논문리뷰
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.5.2" data-path="04_02_Model.html">
            
                <a href="04_02_Model.html">
            
                    
                    02). Model
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >01). You Only Look Once 논문리뷰</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="you-only-look-once---paper-review">You Only Look Once - Paper Review</h1>
<h2 id="01-introduction">01. Introduction</h2>
<p>&#xD574;&#xB2F9; &#xB17C;&#xBB38;&#xC774; &#xB098;&#xC624;&#xAE30; &#xC804;(2015&#xB144; &#xC804;)&#xC5D0;&#xB294; &#xB525;&#xB7EC;&#xB2DD; &#xAE30;&#xBC18;&#xC758; Object Detection System&#xB4E4;&#xC740; Classification &#xBAA8;&#xB378;&#xC744; Object Detection &#xC2DC;&#xC2A4;&#xD15C;&#xC5D0; &#xB9DE;&#xAC8C; &#xBCC0;&#xD615;&#xD55C; &#xBAA8;&#xB378;&#xB4E4;&#xC774; &#xC8FC;&#xB97C; &#xC774;&#xB8E8;&#xC5C8;&#xC2B5;&#xB2C8;&#xB2E4;. Classification &#xBAA8;&#xB378;&#xC744; &#xBCC0;&#xD615;&#xD55C; &#xC2DC;&#xC2A4;&#xD15C;&#xC740; &#xB2E4;&#xC591;&#xD55C; &#xC704;&#xCE58; &#xBC0F; &#xD06C;&#xAE30;&#xC5D0; &#xB300;&#xD574;&#xC11C; &#xD559;&#xC2B5;&#xD558;&#xACE0; &#xD14C;&#xC2A4;&#xD2B8;&#xB97C; &#xC9C4;&#xD589;&#xD588;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p>&#xB300;&#xBD80;&#xBD84;&#xC758; &#xBCC0;&#xD615;&#xB41C; &#xBAA8;&#xB378;&#xB4E4;&#xC740; <a href="https://www.cs.cmu.edu/~deva/papers/dpm_acm.pdf" target="_blank">Deformable Parts Models(DPM)</a>&#xC774; sliding window &#xBC29;&#xBC95;&#xB860;&#xC744; &#xC0AC;&#xC6A9;&#xD558;&#xC5EC; &#xC804;&#xCCB4; &#xC774;&#xBBF8;&#xC9C0;&#xB97C; Classifier&#xB85C; &#xC2A4;&#xCE94;&#xD558;&#xB294; &#xBC29;&#xC2DD; &#xD615;&#xD0DC;&#xC758; &#xBC29;&#xBC95;&#xB860;&#xC744; &#xC0AC;&#xC6A9;&#xD588;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p>&#x200B;    </p>
<p align="center"><img src="https://user-images.githubusercontent.com/13328380/49448628-a96bff00-f81c-11e8-8d54-3435f1c2a3e4.gif"></p>

<center>
    <a href="https://www.pyimagesearch.com/2015/03/23/sliding-windows-for-object-detection-with-python-and-opencv/" target="_blank">
    [sliding window approach]    
    </a>
</center>

<p>&#x200B;    </p>
<p>&#xC81C;&#xC77C; &#xCD5C;&#xADFC;(2015&#xB144;)&#xC758; &#xBAA8;&#xB378;&#xB85C;&#xB294; <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xC774; &#xC788;&#xB294;&#xB370;, <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xC740; bounding box&#xC77C; &#xD655;&#xB960;&#xC774; &#xB192;&#xC740; &#xACF3;&#xC744; &#xC81C;&#xC548;&#xD558;&#xACE0; &#xC81C;&#xC548;&#xB41C; box&#xC601;&#xC5ED;&#xC744; Classifier&#xB85C; &#xB123;&#xC5B4; classification&#xC744; &#xC218;&#xD589;&#xD569;&#xB2C8;&#xB2E4;. &#xADF8; &#xB2E4;&#xC74C; &#xD6C4;&#xCC98;&#xB9AC;&#xB97C; &#xD1B5;&#xD574;&#xC11C; bounding box&#xB97C; &#xAC1C;&#xC120;(&#xD569;&#xCE58;&#xACE0;, &#xC81C;&#xAC70;&#xD558;&#xACE0;)&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC744; &#xC0AC;&#xC6A9;&#xD569;&#xB2C8;&#xB2E4;.</p>
<p><a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xBAA8;&#xB378;&#xC740; region proposal  / classification / box regression&#xB77C;&#xB294; 3&#xAC00;&#xC9C0;  &#xB2E8;&#xACC4;&#xB97C; &#xAC70;&#xCE58;&#xB294; &#xACFC;&#xC815;&#xC744; &#xAC00;&#xC9C0;&#xBA70;, 3&#xAC00;&#xC9C0; &#xB2E8;&#xACC4;&#xB97C; &#xAC1C;&#xBCC4;&#xC801;&#xC73C;&#xB85C; &#xD559;&#xC2B5;&#xD574;&#xC57C;&#xD558;&#xBBC0;&#xB85C; &#xBCF5;&#xC7A1;&#xD55C; &#xD30C;&#xC774;&#xD504;&#xB77C;&#xC778;&#xC744; &#xAC16;&#xAC8C;&#xB429;&#xB2C8;&#xB2E4;. <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xC740; &#xC774;&#xB7F0; &#xBCF5;&#xC7A1;&#xD55C; &#xD30C;&#xC774;&#xD504;&#xB77C;&#xC778; &#xB54C;&#xBB38;&#xC5D0; &#xCD5C;&#xC801;&#xD654;&#xC5D0; &#xC5B4;&#xB835;&#xACE0; &#xAD49;&#xC7A5;&#xD788; &#xD070; inference time&#xC744; &#xAC16;&#xB294;&#xB2E4;&#xB294; &#xB2E8;&#xC810;&#xC774; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49448834-0962a580-f81d-11e8-9926-e6cd2a5fe646.jpg" alt="R-CNN"></p>
<center>
    <a href="https://jamiekang.github.io/2017/05/28/faster-r-cnn/" target="_blank">
    [R-CNN]    
    </a>
</center>

<p>&#x200B;    </p>
<p>You Only Look Once(&#xC774;&#xD558; YOLO)&#xB294; &#xAE30;&#xC874;&#xC758; &#xBC29;&#xBC95;&#xB860;&#xC778; Classification&#xBAA8;&#xB378;&#xC744; &#xBCC0;&#xD615;&#xD55C; &#xBC29;&#xBC95;&#xB860;&#xC5D0;&#xC11C; &#xBC97;&#xC5B4;&#xB098;, Object Detection &#xBB38;&#xC81C;&#xB97C; regression&#xBB38;&#xC81C;&#xB85C; &#xC815;&#xC758;&#xD558;&#xB294; &#xAC83;&#xC744; &#xD1B5;&#xD574;&#xC11C; &#xC774;&#xBBF8;&#xC9C0;&#xC5D0;&#xC11C; &#xC9C1;&#xC811;&#xC801;&#xC73C;&#xB85C; bounding box &#xC88C;&#xD45C;&#xC640; &#xAC01; &#xD074;&#xB798;&#xC2A4;&#xC758; &#xD655;&#xB960;&#xC744; &#xAD6C;&#xD569;&#xB2C8;&#xB2E4;.</p>
<p>YOLO&#xB294; End-to-End &#xBC29;&#xC2DD;&#xC758; &#xD1B5;&#xD569;&#xB41C; &#xAD6C;&#xC870;&#xB97C; &#xAC00;&#xC9C0;&#xACE0; &#xC788;&#xC73C;&#xBA70;, &#xC774;&#xBBF8;&#xC9C0;&#xB97C; convolutional neural network&#xC5D0; &#xD55C;&#xBC88; &#xD3C9;&#xAC00;(inference)&#xD558;&#xB294; &#xAC83;&#xC744; &#xD1B5;&#xD574;&#xC11C; &#xB3D9;&#xC2DC;&#xC5D0; &#xB2E4;&#xC218;&#xC758; bounding box&#xC640; class &#xD655;&#xB960;&#xC744; &#xAD6C;&#xD558;&#xAC8C;&#xB429;&#xB2C8;&#xB2E4;. &#xC774;&#xB807;&#xAC8C; &#xD1B5;&#xD569;&#xB41C; &#xBAA8;&#xB378;&#xB85C; &#xC778;&#xD574;&#xC11C;  YOLO&#xB294; &#xBA87;&#xAC00;&#xC9C0; &#xC7A5;&#xC810;&#xC744; &#xAC00;&#xC9C0;&#xAC8C; &#xB429;&#xB2C8;&#xB2E4;.</p>
<p>&#xCCAB;&#xBC88;&#xC9F8;&#xB85C; Titan X&#xC5D0;&#xC11C; 45fps&#xB97C; &#xB2EC;&#xC131;&#xD558;&#xBA70; &#xBE60;&#xB978;&#xBC84;&#xC804;&#xC758; &#xACBD;&#xC6B0; 150fps&#xC758; &#xBE60;&#xB978; &#xC131;&#xB2A5;&#xC744; &#xC790;&#xB791;&#xD568;&#xACFC; &#xB3D9;&#xC2DC;&#xC5D0; &#xB2E4;&#xB978; &#xC2E4;&#xC2DC;&#xAC04; &#xC2DC;&#xC2A4;&#xD15C; &#xB300;&#xBE44; 2&#xBC30; &#xC774;&#xC0C1;&#xC758; mAP(mean average precision)&#xB97C; &#xB192;&#xC740; &#xC131;&#xB2A5;&#xC744; &#xBCF4;&#xC5EC;&#xC90D;&#xB2C8;&#xB2E4;.</p>
<p>&#xB450;&#xBC88;&#xC9F8;&#xB85C;&#xB294;. sliding window&#xBC29;&#xC2DD;&#xC774; &#xC544;&#xB2CC; convolutional neural network&#xB97C; &#xC0AC;&#xC6A9;&#xD558;&#xB294; &#xAC83;&#xC73C;&#xB85C; &#xC778;&#xD574; &#xC804;&#xCCB4; &#xC774;&#xBBF8;&#xC9C0;&#xB97C; &#xBCF4;&#xAC8C;&#xB054; &#xC720;&#xB3C4;&#xB418;&#xC5B4;(&#xBB38;&#xB9E5;&#xC815;&#xBCF4;;contextual information)&#xAC01; class&#xC5D0; &#xB300;&#xD55C; &#xD45C;&#xD604;&#xC744; &#xB354; &#xC798; &#xD559;&#xC2B5;&#xD558;&#xAC8C;&#xB429;&#xB2C8;&#xB2E4;. (<a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xC758; &#xACBD;&#xC6B0;&#xC5D0;&#xB294; &#xC774;&#xBBF8;&#xC9C0;&#xC758; &#xBC31;&#xADF8;&#xB77C;&#xC6B4;&#xB4DC;&#xC5D0; &#xC758;&#xD574;&#xC11C; Object Detection&#xC744; &#xC2E4;&#xD328;&#xD558;&#xB294; &#xACBD;&#xC6B0;&#xAC00; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;.)</p>
<p>&#xC138;&#xBC88;&#xC9F8;&#xB85C;&#xB294; &#xC77C;&#xBC18;&#xD654;&#xB41C; Object&#xC758; &#xD45C;&#xD604;&#xC744; &#xD559;&#xC2B5;&#xD569;&#xB2C8;&#xB2E4;. &#xC2E4;&#xD5D8;&#xC801;&#xC73C;&#xB85C; &#xC790;&#xC5F0;&#xC758; dataset&#xC744; &#xD559;&#xC2B5;&#xC2DC;&#xD0A8; &#xC774;&#xD6C4;&#xC5D0; &#xD559;&#xC2B5;&#xC2DC;&#xD0A8; &#xB124;&#xD2B8;&#xC6CC;&#xD06C;&#xC5D0; artwork &#xC774;&#xBBF8;&#xC9C0;&#xB97C; &#xC785;&#xB825;&#xD588;&#xC744; &#xB54C;, <a href="https://www.cs.cmu.edu/~deva/papers/dpm_acm.pdf" target="_blank">DPM</a>, <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a> &#xB300;&#xBE44; &#xB9CE;&#xC740; &#xACA9;&#xCC28;&#xB85C; &#xC88B;&#xC740; Detection &#xC131;&#xB2A5;&#xC744; &#xBCF4;&#xC5EC;&#xC90D;&#xB2C8;&#xB2E4;.</p>
<p>&#x200B;    </p>
<p>YOLO&#xC5D0; &#xB300;&#xD55C; &#xD2B9;&#xC9D5;&#xC744; &#xC815;&#xB9AC;&#xD574;&#xBCF4;&#xC790;&#xBA74; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<ul>
<li>state-of-the-art&#xC5D0;&#xB294; &#xBABB;&#xBBF8;&#xCE58;&#xB294; &#xC131;&#xB2A5;</li>
<li>&#xBE60;&#xB978; inference</li>
<li>&#xC791;&#xC740; &#xBB3C;&#xCCB4;&#xC5D0; &#xB300;&#xD574;&#xC11C; Detection &#xC131;&#xB2A5;&#xC774; &#xB5A8;&#xC5B4;&#xC9D0;</li>
<li>end-to-end &#xD615;&#xD0DC;&#xC758; inference&#xC640; train</li>
<li>&#xC88B;&#xC740; &#xC77C;&#xBC18;&#xD654; &#xC131;&#xB2A5;</li>
</ul>
<h2 id="02-unified-detection">02. Unified Detection</h2>
<p> YOLO&#xC758; &#xD575;&#xC2EC;&#xC740; <code>Unified Detection</code> &#xC785;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; YOLO&#xAC00; <code>Unified Detection</code>&#xAC00; &#xB420; &#xC218; &#xC788;&#xC5C8;&#xB358; &#xAC83;&#xC5D0;&#xB294; convolutional neural network&#xAC00; &#xAC00;&#xC7A5; &#xC911;&#xC694;&#xD55C; &#xC5ED;&#xD560;&#xC744; &#xD569;&#xB2C8;&#xB2E4;. YOLO&#xB294; &#xB2E8;&#xC77C;  convolutional neural network &#xBAA8;&#xB378; &#xD558;&#xB098;&#xB85C; (object detection &#xBB38;&#xC81C;&#xB97C; &#xD480;&#xAE30; &#xC704;&#xD55C;) &#xD2B9;&#xC9D5; &#xCD94;&#xCD9C;, &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4; &#xACC4;&#xC0B0;, &#xD074;&#xB798;&#xC2A4; &#xBD84;&#xB958;&#xB97C; &#xBAA8;&#xB450; &#xC218;&#xD589;&#xD569;&#xB2C8;&#xB2E4;. &#xC989; &#xC6D0;&#xBCF8; &#xC774;&#xBBF8;&#xC9C0;&#xB97C; &#xC785;&#xB825;&#xC73C;&#xB85C; &#xBC1B;&#xC740; &#xBAA8;&#xB378;&#xC774; object detection&#xC5D0; &#xD544;&#xC694;&#xD55C; &#xBAA8;&#xB4E0; &#xC5F0;&#xC0B0;&#xC744; &#xC218;&#xD589;&#xD560; &#xC218; &#xC788;&#xB2E4;&#xB294; &#xC758;&#xBBF8;&#xC774;&#xBA70;, &#xC774;&#xAC83;&#xC774; &#xBC14;&#xB85C; YOLO&#xC5D0;&#xC11C; &#xC8FC;&#xC7A5;&#xD558;&#xB294; <code>Unified Detection</code>&#xC758; &#xAC1C;&#xB150;&#xC785;&#xB2C8;&#xB2E4;.</p>
<p> YOLO&#xC5D0;&#xB294; &#xAE30;&#xC874;&#xC758; &#xBAA8;&#xB378;&#xC5D0;&#xB294; &#xC5C6;&#xC5C8;&#xB358; &#xB2E4;&#xC591;&#xD55C; &#xC774;&#xC810;&#xB4E4;&#xC774; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC6B0;&#xC120; &#xBAA8;&#xB378;&#xC774; &#xC774;&#xBBF8;&#xC9C0; &#xC804;&#xCCB4;&#xB97C; &#xBCF4;&#xACE0; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC608;&#xCE21;&#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC989; &#xBAA8;&#xB378;&#xC774; &#xC774;&#xBBF8;&#xC9C0;&#xC758; &#xC804;&#xC5ED;&#xC801;&#xC778; &#xD2B9;&#xC9D5;&#xC744; &#xC798; &#xC774;&#xC6A9;&#xD574;&#xC11C; &#xCD94;&#xB860;&#xC744; &#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; <code>Unified Detection</code>&#xC774;&#xB77C;&#xB294; &#xC6A9;&#xC5B4; &#xADF8;&#xB300;&#xB85C; &#xBAA8;&#xB378;&#xC740; bounding box regression&#xACFC; multi-class classification&#xC744; &#xB3D9;&#xC2DC;&#xC5D0; &#xC218;&#xD589;&#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774;&#xB7EC;&#xD55C; &#xC774;&#xC810;&#xB4E4;&#xB85C; &#xC778;&#xD558;&#xC5EC; YOLO&#xB294; &#xB192;&#xC740; mAP&#xB97C; &#xC720;&#xC9C0;&#xD558;&#xBA74;&#xC11C;, end-to-end &#xD559;&#xC2B5;&#xC774; &#xAC00;&#xB2A5;&#xD558;&#xACE0;, &#xC2E4;&#xC2DC;&#xAC04;&#xC758; &#xCD94;&#xB860; &#xC18D;&#xB3C4;&#xAC00; &#xAC00;&#xB2A5;&#xD55C; &#xAC83;&#xC785;&#xB2C8;&#xB2E4;.  </p>
<p> &#xC9C0;&#xAE08;&#xBD80;&#xD130;&#xB294; YOLO &#xBAA8;&#xB378;&#xC744; &#xC2EC;&#xB3C4;&#xAE4A;&#xAC8C; &#xC54C;&#xC544;&#xBCF4;&#xB3C4;&#xB85D; &#xD558;&#xACA0;&#xC2B5;&#xB2C8;&#xB2E4;. YOLO &#xBAA8;&#xB378;&#xC5D0;&#xC11C;&#xB294; &#xC785;&#xB825; &#xC774;&#xBBF8;&#xC9C0;&#xB97C; S x S &#xADF8;&#xB9AC;&#xB4DC;&#xB85C; &#xB098;&#xB215;&#xB2C8;&#xB2E4;. &#xB9CC;&#xC57D; &#xC5B4;&#xB5A4; &#xAC1D;&#xCCB4;&#xC758; &#xC911;&#xC810;&#xC774; &#xD2B9;&#xC815; &#xADF8;&#xB9AC;&#xB4DC; &#xC140; &#xC548;&#xC5D0; &#xC874;&#xC7AC;&#xD55C;&#xB2E4;&#xBA74;, &#xD574;&#xB2F9; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC774; &#xADF8; &#xAC1D;&#xCCB4;&#xB97C; &#xAC80;&#xCD9C;&#xD574;&#xC57C; &#xD569;&#xB2C8;&#xB2E4;. &#xAC01; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC740; B&#xAC1C;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; &#xAC01; &#xBC14;&#xC6B4;&#xB529;&#xBC15;&#xC2A4; &#xB9C8;&#xB2E4; <code>confidence scores</code>&#xB97C; &#xC608;&#xCE21;&#xD558;&#xB294;&#xB370;, <code>confidence scores</code>&#xB780; &#xD574;&#xB2F9; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4; &#xB0B4;&#xC5D0; &#xAC1D;&#xCCB4;&#xAC00; &#xC874;&#xC7AC;&#xD560; &#xD655;&#xB960;&#xC744; &#xC758;&#xBBF8;&#xD558;&#xBA70; 0&#xC5D0;&#xC11C; 1 &#xC0AC;&#xC774;&#xC758; &#xAC12;&#xC744; &#xAC00;&#xC9D1;&#xB2C8;&#xB2E4;. <code>confidence scores</code>&#xB97C; &#xC218;&#xC2DD;&#xC801;&#xC73C;&#xB85C; &#xB098;&#xD0C0;&#xB0B4;&#xBA74; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<blockquote>
<p>Pr(Object) &#x2217; IOU_truth^pred (1)</p>
</blockquote>
<p>&#xB9CC;&#xC57D; &#xC5B4;&#xB5A4; &#xC140; &#xC548;&#xC5D0; &#xAC1D;&#xCCB4;&#xAC00; &#xC5C6;&#xC73C;&#xBA74; <code>confidence scores</code>&#xB294; 0&#xC785;&#xB2C8;&#xB2E4;. &#xB610;&#xD55C; <code>confidence scores</code>&#xB294; &#xBAA8;&#xB378;&#xC774; &#xC608;&#xCE21;&#xD55C; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC640; ground truth &#xAC04;&#xC758; IOU(intersection over union)&#xC774; &#xB3D9;&#xC77C;&#xD560;&#xC218;&#xB85D; &#xC88B;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p>&#xAC01; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB294; &#xAC12; 5&#xAC1C;&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4; : <code>x</code>, <code>y</code>, <code>w</code>, <code>h</code>, <code>confidence</code>. <code>(x, y)</code>&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; &#xC911;&#xC2EC;&#xC810;&#xC774;&#xBA70;, &#xAC01; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xB9C8;&#xB2E4; &#xC0C1;&#xB300;&#xC801;&#xC778; &#xAC12;&#xC73C;&#xB85C; &#xD45C;&#xD604;&#xD569;&#xB2C8;&#xB2E4;. <code>(w, h)</code>&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; width&#xC640; height&#xC778;&#xB370; &#xC804;&#xCCB4; &#xC774;&#xBBF8;&#xC9C0;&#xC5D0; &#xB300;&#xD574; &#xC0C1;&#xB300;&#xC801;&#xC778; &#xAC12;&#xC73C;&#xB85C; &#xD45C;&#xD604;&#xD569;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; <code>confidence</code>&#xB294; &#xC55E;&#xC11C; &#xB2E4;&#xB8EC; <code>confidence score</code>&#xC640; &#xB3D9;&#xC77C;&#xD569;&#xB2C8;&#xB2E4;.</p>
<p>&#xAC01; &#xADF8;&#xB9AC;&#xB4DC;&#xC140;&#xB9C8;&#xB2E4; &#xD655;&#xB960;&#xAC12; C&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. C&#xB294; &#xC870;&#xAC74;&#xBD80; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;(conditional class probabilities)&#xC778; Pr(Class_i|Object)&#xC785;&#xB2C8;&#xB2E4;. YOLO&#xC5D0;&#xC11C;&#xB294; &#xADF8;&#xB9AC;&#xB4DC; &#xB2F9; &#xC608;&#xCE21;&#xD558;&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; &#xAC2F;&#xC218;(B)&#xC640; &#xC0C1;&#xAD00; &#xC5C6;&#xC774; &#xADF8;&#xB9AC;&#xB4DC; &#xB2F9; &#xC624;&#xC9C1; &#xD558;&#xB098;&#xC758; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;&#xB9CC; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;.  </p>
<p>Test time&#xC5D0;&#xC11C;&#xB294; &#xC870;&#xAC74;&#xBD80; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;&#xACFC; &#xAC01; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB294; confidence score&#xB97C; &#xACF1;&#xD574;&#xC8FC;&#xBA70; &#xC774;&#xB294; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC774; &#xB098;&#xD0C0;&#xB0BC; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<blockquote>
<p>Pr(Classi|Object) &#x2217; Pr(Object) &#x2217; IOUtruth pred = Pr(Classi) &#x2217; IOUtruth pred</p>
</blockquote>
<p>&#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB9C8;&#xB2E4; <code>sclass-specific confidence scores</code>&#xB97C; &#xC5BB;&#xC744; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774; &#xC2A4;&#xCF54;&#xC5B4;&#xB294; &#xD574;&#xB2F9; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC5D0;&#xC11C; &#xD2B9;&#xC815; &#xD074;&#xB798;&#xC2A4; &#xAC1D;&#xCCB4;&#xAC00; &#xB098;&#xD0C0;&#xB0A0; &#xD655;&#xB960;&#xACFC;, &#xAC1D;&#xCCB4;&#xC5D0; &#xB9DE;&#xAC8C; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC62C;&#xBC14;&#xB974;&#xAC8C; &#xC608;&#xCE21;&#xD588;&#xB294;&#xC9C0;&#xB97C; &#xB098;&#xD0C0;&#xB0C5;&#xB2C8;&#xB2E4;.    </p>
<p>&#xB17C;&#xBB38;&#xC5D0;&#xC11C;&#xB294; PASCAL VOC&#xB97C; &#xC774;&#xC6A9;&#xD558;&#xC5EC; Evaluation&#xC744; &#xC9C4;&#xD589;&#xD569;&#xB2C8;&#xB2E4;. &#xC774;&#xB97C; &#xC704;&#xD574; S = 7, B = 2, C = 20 &#xC73C;&#xB85C; &#xC124;&#xC815;&#xD569;&#xB2C8;&#xB2E4;. (PASCAL VOC&#xC5D0;&#xB294; 20&#xAC1C;&#xC758; &#xB808;&#xC774;&#xBE14;&#xC774; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;). &#xB530;&#xB77C;&#xC11C; &#xBAA8;&#xB378;&#xC758; output tensor&#xB294; 7 x 7 x 30 &#xC785;&#xB2C8;&#xB2E4;.  </p>
<h3 id="0201-network-design">02.01. Network Design</h3>
<p> &#xC55E;&#xC11C; &#xB9D0;&#xC500;&#xB4DC;&#xB838;&#xB4EF;&#xC774; YOLO&#xB294; convolutional neural network&#xB85C; &#xB514;&#xC790;&#xC778;&#xB41C; &#xBAA8;&#xB378;&#xC785;&#xB2C8;&#xB2E4;. YOLO&#xB294; &#xC55E;&#xB2E8;&#xC758; convolutional layers&#xC640; &#xB4B7;&#xB2E8;&#xC758; fully connected layers&#xB85C; &#xAD6C;&#xC131;&#xB429;&#xB2C8;&#xB2E4;. convolutional layers&#xB294; &#xC774;&#xBBF8;&#xC9C0;&#xC5D0;&#xC11C; &#xD2B9;&#xC9D5;&#xC744; &#xCD94;&#xCD9C;&#xD558;&#xACE0;, fully connected layers&#xB294; &#xCD94;&#xCD9C;&#xB41C; &#xD2B9;&#xC9D5;&#xC744; &#xAE30;&#xBC18;&#xC73C;&#xB85C; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;&#xACFC; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; &#xC88C;&#xD45C;&#xB97C; &#xCD94;&#xB860;&#xD569;&#xB2C8;&#xB2E4;. YOLO&#xB294; 24&#xAC1C;&#xC758; convolutional layers&#xC640; 2&#xAC1C;&#xC758; fully connected layers&#xB85C; &#xAD6C;&#xC131;&#xB429;&#xB2C8;&#xB2E4;. YOLO&#xBAA8;&#xB378;&#xC740; &#xC544;&#xB798;&#xC640; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p> <img src="https://user-images.githubusercontent.com/13328380/48620356-3290d280-e9e3-11e8-8488-0d17e57da49b.PNG" alt="YOLO model"></p>
<p> &#xB17C;&#xBB38;&#xC5D0;&#xC11C;&#xB294; YOLO&#xBCF4;&#xB2E4; &#xC18D;&#xB3C4;&#xAC00; &#xBE60;&#xB978; &#xBC84;&#xC804;&#xC778; Fast YOLO&#xB3C4; &#xC18C;&#xAC1C;&#xD569;&#xB2C8;&#xB2E4;. Fast YOLO&#xB294; YOLO&#xC5D0;&#xC11C; &#xB2E8;&#xC21C;&#xD788; &#xB808;&#xC774;&#xC5B4;&#xC758; &#xAC2F;&#xC218;&#xB97C; &#xC904;&#xC778; &#xBAA8;&#xB378;&#xC778;&#xB370; 9&#xAC1C;&#xC758; convolutional layer(&#xAE30;&#xC874; 24)&#xB97C; &#xAC00;&#xC9C4; &#xBAA8;&#xB378;&#xC785;&#xB2C8;&#xB2E4;.</p>
<h3 id="0202-training">02.02. Training</h3>
<p>&#xC774;&#xBC88; &#xC7A5;&#xC5D0;&#xC11C;&#xB294; YOLO&#xC758; &#xD559;&#xC2B5;&#xACFC;&#xC815;&#xC744; &#xC0B4;&#xD3B4;&#xBCF4;&#xACA0;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<h4 id="020201-pretraining-network">02.02.01) Pretraining Network</h4>
<p> YOLO &#xBAA8;&#xB378;&#xC758; cnvolutional layers&#xB294; ImageNet Dataset&#xC73C;&#xB85C; Pretrain &#xD569;&#xB2C8;&#xB2E4;. 24&#xAC1C;&#xC758; convolutional layers &#xC911; &#xC55E;&#xB2E8;&#xC758; 20&#xAC1C;&#xC758; convolutional layers&#xB97C; pretrain&#xD569;&#xB2C8;&#xB2E4;. 20&#xAC1C;&#xC758; convolutional layers &#xB4B7;&#xB2E8;&#xC5D0; average-pooling layer&#xC640; fully connected layer&#xB97C; &#xBD99;&#xD600;&#xC11C; ImageNet&#xC758; 1000&#xAC1C;&#xC758; class&#xB97C; &#xBD84;&#xB958;&#xD558;&#xB294; &#xB124;&#xD2B8;&#xC6CC;&#xD06C;&#xB97C; &#xB9CC;&#xB4E4;&#xACE0; &#xC774;&#xB97C; &#xD559;&#xC2B5;&#xC2DC;&#xD0B5;&#xB2C8;&#xB2E4;. (&#xB17C;&#xBB38; &#xAE30;&#xC900; 1&#xC8FC;&#xC77C;&#xAC04; &#xD559;&#xC2B5; &#xD6C4; ImageNet 2012 validation set &#xAE30;&#xC900; top-5 accuracy 88%) YOLO&#xB294; &#xC55E;&#xB2E8; 20&#xAC1C;&#xC758; pretrained convolutional layer&#xC5D0; 4&#xAC1C;&#xC758; convolutional layer&#xC640; 2&#xAC1C;&#xC758; fully connected layer&#xB97C; &#xCD94;&#xAC00;&#xD558;&#xC5EC; &#xAD6C;&#xC131;&#xD569;&#xB2C8;&#xB2E4;. &#xC774;&#xB54C; &#xC0C8;&#xB85C; &#xCD94;&#xAC00;&#xB41C; &#xB808;&#xC774;&#xC5B4;&#xB294; random initialized weights&#xB85C; &#xCD08;&#xAE30;&#xD654;&#xD569;&#xB2C8;&#xB2E4;.</p>
<h4 id="020202-normalized-bounding-boxes">02.02.02) Normalized Bounding Boxes</h4>
<p>&#xBAA8;&#xB378;&#xC740; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;&#xAC12;&#xACFC; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4; &#xC88C;&#xD45C;&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. YOLO &#xC5D0;&#xC11C;&#xB294; &#xC815;&#xADDC;&#xD654;&#xB41C;(normalized) &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC0AC;&#xC6A9;&#xD569;&#xB2C8;&#xB2E4;. &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; width&#xC640; height&#xB294; &#xAC01;&#xAC01; &#xC774;&#xBBF8;&#xC9C0;&#xC758; width&#xC640; height&#xB85C; &#xC815;&#xADDC;&#xD654;&#xC2DC;&#xD0B5;&#xB2C8;&#xB2E4;. &#xB530;&#xB77C;&#xC11C; &#xAC12;&#xC740; 0&#xC5D0;&#xC11C; 1 &#xC0AC;&#xC774;&#xC758; &#xAC12;&#xC785;&#xB2C8;&#xB2E4;. &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; &#xC911;&#xC2EC; &#xC88C;&#xD45C;&#xC778; x&#xC640; y&#xB294; &#xD2B9;&#xC815; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC5D0;&#xC11C;&#xC758; offset&#xC73C;&#xB85C; &#xB098;&#xD0C0;&#xB0C5;&#xB2C8;&#xB2E4;. &#xB530;&#xB77C;&#xC11C; &#xC774; &#xAC12;&#xB3C4; 0&#xC5D0;&#xC11C; 1 &#xC0AC;&#xC774;&#xC758; &#xAC12;&#xC785;&#xB2C8;&#xB2E4;.</p>
<h4 id="020203-nolinearity">02.02.03) Nolinearity</h4>
<p>YOLO&#xC758; activation function&#xC740; leaky ReLU&#xB97C; &#xC0AC;&#xC6A9;&#xD558;&#xBA70;, &#xB2E8; &#xB9C8;&#xC9C0;&#xB9C9; &#xB808;&#xC774;&#xC5B4;&#xB9CC; linear activation function&#xC744; &#xC0AC;&#xC6A9;&#xD569;&#xB2C8;&#xB2E4;. leaky ReLU&#xC758; &#xC218;&#xC2DD;&#xC740; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p><img src="https://user-images.githubusercontent.com/15168540/49425352-a3582d00-f7e0-11e8-9582-719a4e84b715.png" alt="image"></p>
<h4 id="020204-&#xACE0;&#xB824;&#xD574;&#xC57C;-&#xD560;-&#xC0AC;&#xD56D;&#xB4E4;">02.02.04) &#xACE0;&#xB824;&#xD574;&#xC57C; &#xD560; &#xC0AC;&#xD56D;&#xB4E4;</h4>
<p>YOLO&#xC758; loss&#xB294; <code>Sum-squared error</code>&#xB97C; &#xAE30;&#xBC18;&#xC73C;&#xB85C; &#xD569;&#xB2C8;&#xB2E4;. YOLO&#xC758; loss&#xC5D0;&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC5BC;&#xB9C8;&#xB098; &#xC798; &#xC608;&#xCE21;&#xD588;&#xB294;&#xC9C0;&#xC5D0; &#xB300;&#xD55C; loss&#xC778; <code>localization loss</code>&#xC640; &#xD074;&#xB798;&#xC2A4;&#xB97C; &#xC5BC;&#xB9C8;&#xB098; &#xC798; &#xC608;&#xCE21;&#xD588;&#xB294;&#xC9C0;&#xC5D0; &#xB300;&#xD55C; loss&#xC778; <code>classification loss</code>&#xAC00; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774; &#xB450; &#xAC1C;&#xC758; loss&#xC5D0; &#xB3D9;&#xC77C;&#xD55C; &#xAC00;&#xC911;&#xCE58;&#xB97C; &#xD560;&#xB2F9;&#xD558;&#xACE0; &#xD559;&#xC2B5;&#xC2DC;&#xD0A4;&#xB294; &#xAC83;&#xC740; &#xC88B;&#xC9C0; &#xC54A;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p>&#xB610; &#xB2E4;&#xB978; &#xBB38;&#xC81C;&#xB3C4; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. YOLO&#xC5D0;&#xC11C;&#xB294; S x S&#xAC1C;&#xC758; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC744; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. &#xAC70;&#xC758; &#xBAA8;&#xB4E0; &#xC774;&#xBBF8;&#xC9C0;&#xC5D0;&#xC11C; &#xB300;&#xB2E4;&#xC218;&#xC758; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC5D0;&#xB294; &#xAC1D;&#xCCB4;&#xAC00; &#xC874;&#xC7AC;&#xD558;&#xC9C0; &#xC54A;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774;&#xB7F0; &#xBD88;&#xADE0;&#xD615;&#xC740; YOLO&#xAC00; &#xBAA8;&#xB4E0; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC5D0;&#xC11C; <code>confidence = 0</code>&#xC774;&#xB77C;&#xACE0; &#xC608;&#xCE21;&#xD558;&#xB3C4;&#xB85D; &#xD559;&#xC2B5;&#xB418;&#xAC8C; &#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. YOLO&#xC5D0;&#xC11C;&#xB294; &#xC774;&#xB97C; &#xD574;&#xACB0;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C; &#xAC1D;&#xCCB4;&#xAC00; &#xC874;&#xC7AC;&#xD558;&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; <code>confidence loss</code> &#xAC00;&#xC911;&#xCE58;&#xB97C; &#xB298;&#xB9AC;&#xACE0; &#xBC18;&#xB300;&#xB85C; &#xAC1D;&#xCCB4;&#xAC00; &#xC874;&#xC7AC;&#xD558;&#xC9C0; &#xC54A;&#xB294; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; <code>confidence loss</code> &#xAC00;&#xC911;&#xCE58;&#xB97C; &#xC904;&#xC785;&#xB2C8;&#xB2E4;. &#xC774;&#xB294; &#xC2E4;&#xC81C;&#xB85C; &#xB450;&#xAC00;&#xC9C0; &#xD30C;&#xB77C;&#xBBF8;&#xD130;&#xB85C; &#xC870;&#xC808;&#xD560; &#xC218; &#xC788;&#xB294;&#xB370;, <code>&#x3BB;_coord</code>&#xC640; <code>&#x3BB;_noobj</code> &#xC785;&#xB2C8;&#xB2E4;. &#xB17C;&#xBB38;&#xC5D0;&#xC11C;&#xB294; <code>&#x3BB;_coord = 5</code>, <code>&#x3BB;_noobj = .5</code>&#xB85C; &#xC124;&#xC815;&#xD569;&#xB2C8;&#xB2E4;.</p>
<p><code>Sum-squared error</code>&#xB97C; &#xC0AC;&#xC6A9;&#xD558;&#xBA74; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xAC00; &#xD070; &#xAC1D;&#xCCB4;&#xC640; &#xC791;&#xC740; &#xAC1D;&#xCCB4;&#xC5D0; &#xB3D9;&#xC77C;&#xD55C; &#xAC00;&#xC911;&#xCE58;&#xB97C; &#xC8FC;&#xB294; &#xACBD;&#xC6B0;&#xC5D0;&#xB3C4; &#xBB38;&#xC81C;&#xAC00; &#xC0DD;&#xAE38; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC791;&#xC740; &#xAC1D;&#xCCB4; &#xBC14;&#xC6B4;&#xB529;&#xBC15;&#xC2A4;&#xB294; &#xC870;&#xAE08;&#xB9CC; &#xC5B4;&#xAE0B;&#xB098;&#xB3C4; &#xACB0;&#xACFC;&#xC5D0; &#xD070; &#xC601;&#xD5A5;&#xC744; &#xC8FC;&#xC9C0;&#xB9CC; &#xD070; &#xAC1D;&#xCCB4;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC758; &#xACBD;&#xC6B0;&#xC5D0;&#xB294; &#xADF8;&#xB807;&#xC9C0; &#xC54A;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774;&#xB97C; &#xD574;&#xACB0;&#xD558;&#xAE30; &#xC704;&#xD574;&#xC11C; YOLO&#xC5D0;&#xC11C;&#xB294; <code>width</code>&#xC640; <code>height</code>&#xC5D0; <code>square root</code>&#xB97C; &#xC50C;&#xC6C1;&#xB2C8;&#xB2E4;.</p>
<h4 id="020205-multiple-bounding-boxes-per-gridcell">02.02.05) Multiple bounding boxes per gridcell</h4>
<p>YOLO&#xB294; &#xD558;&#xB098;&#xC758; &#xADF8;&#xB9AC;&#xB4DC; &#xC140; &#xB2F9; &#xC5EC;&#xB7EC;&#xAC1C;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. Train time&#xC5D0;&#xC11C;&#xB294; &#xAC1D;&#xCCB4; &#xD558;&#xB098; &#xB2F9; &#xD558;&#xB098;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC640; &#xB9E4;&#xCE6D;&#xC2DC;&#xCF1C;&#xC57C; &#xD558;&#xBBC0;&#xB85C;, &#xC5EC;&#xB7EC;&#xAC1C;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4; &#xC911; &#xD558;&#xB098;&#xB97C; &#xC120;&#xD0DD;&#xD574;&#xC57C; &#xD569;&#xB2C8;&#xB2E4;. &#xC774;&#xB97C; &#xC704;&#xD574;(&#xB3D9;&#xC77C;&#xD55C; &#xADF8;&#xB9AC;&#xB4DC; &#xB0B4;)&#xC5EC;&#xB7EC; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4; &#xC911; gorund-truth&#xC640;&#xC758; IOU&#xAC00; &#xAC00;&#xC7A5; &#xB192;&#xC740; &#xD558;&#xB098;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB9CC; &#xC120;&#xD0DD;&#xD569;&#xB2C8;&#xB2E4;. &#xC774;&#xB97C; &#xD1B5;&#xD574; &#xB3D9;&#xC77C;&#xD55C; &#xADF8;&#xB9AC;&#xB4DC; &#xB0B4; &#xC5EC;&#xB7EC; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xAC00; &#xC11C;&#xB85C; &#xB2E4;&#xB978; &#xAC1D;&#xCCB4;&#xC758; &#xC0AC;&#xC774;&#xC988;, &#xC885;&#xD6A1;&#xBE44;(acpect ratios), &#xAC1D;&#xCCB4; &#xD074;&#xB798;&#xC2A4;&#xB97C; &#xC608;&#xCE21;&#xD558;&#xAC8C; &#xD558;&#xC5EC; overall recall&#xC744; &#xC0C1;&#xC2B9;&#xC2DC;&#xD0AC; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;.    </p>
<h4 id="020206-loss-function">02.02.06) Loss Function</h4>
<p>Train time&#xC5D0; &#xC0AC;&#xC6A9;&#xD558;&#xB294; loss function&#xC740; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.  </p>
<p><img src="https://user-images.githubusercontent.com/13328380/48620401-62d87100-e9e3-11e8-8975-93ec5b4eccf8.PNG" alt="Objective function"></p>
<p>&#xC5EC;&#xAE30;&#xC5D0;&#xC11C; <code>1_obj^i</code> &#xB294; i&#xBC88;&#xC9F8; &#xADF8;&#xB9AC;&#xB4DC; &#xC140; &#xC5D0; &#xC788;&#xB294; j&#xBC88;&#xC9F8; &#xBC14;&#xC6B4;&#xB529;&#xBC15;&#xC2A4;&#xC5D0; &#xAC1D;&#xCCB4;&#xAC00; &#xC874;&#xC7AC;&#xD558;&#xB294;&#xC9C0;&#xB97C; &#xB098;&#xD0C0;&#xB0C5;&#xB2C8;&#xB2E4;. &#xAC00;&#xB839; <code>1_obj^i = 1</code>&#xC778; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB294; &#xD574;&#xB2F9; &#xAC1D;&#xCCB4;&#xB97C; &#xAC80;&#xCD9C;&#xD574; &#xB0B4;&#xC57C; &#xD569;&#xB2C8;&#xB2E4;.</p>
<p>&#xC218;&#xC2DD;&#xC758; <code>classification loss</code>&#xC758; &#xACBD;&#xC6B0;&#xC5D0;&#xB294; <code>1_obj^i = 1</code>&#xC778; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC5D0;&#xB9CC; &#xC801;&#xC6A9;&#xC774; &#xB418;&#xB294; loss&#xC785;&#xB2C8;&#xB2E4;(&#xC774;&#xB294; Pr(Class_i|Object)&#xB97C; &#xBC18;&#xC601;&#xD55C; &#xACB0;&#xACFC;&#xC785;&#xB2C8;&#xB2E4;). &#xB610;&#xD55C; <code>borunding box coordinate loss</code>&#xC758; &#xACBD;&#xC6B0;&#xC5D0;&#xB3C4; &#xC704;&#xC640; &#xB9C8;&#xCC2C;&#xAC00;&#xC9C0; &#xC785;&#xB2C8;&#xB2E4;.</p>
<h4 id="020207-&#xD559;&#xC2B5;-&#xBC0F;-&#xD558;&#xC774;&#xD37C;-&#xD30C;&#xB77C;&#xBBF8;&#xD130;">02.02.07) &#xD559;&#xC2B5; &#xBC0F; &#xD558;&#xC774;&#xD37C; &#xD30C;&#xB77C;&#xBBF8;&#xD130;</h4>
<p>&#xB17C;&#xBB38;&#xC5D0;&#xC11C;&#xB294; PASCAL VOC 2007 / 2012&#xC744; &#xC774;&#xC6A9;&#xD574;&#xC11C; &#xCD1D; 135 epochs&#xB97C; &#xD559;&#xC2B5;&#xC2DC;&#xCF30;&#xC2B5;&#xB2C8;&#xB2E4;. &#xD558;&#xC774;&#xD37C; &#xD30C;&#xB77C;&#xBBF8;&#xD130; &#xC138;&#xD305;&#xC740; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<p><code>batch size = 64</code><br><code>momentum of 0.9</code><br><code>decay = 0.0005</code></p>
<h4 id="020208-&#xD559;&#xC2B5;&#xB960;-&#xC2A4;&#xCF00;&#xC904;&#xB9C1;learning-rate-scheduling">02.02.08) &#xD559;&#xC2B5;&#xB960; &#xC2A4;&#xCF00;&#xC904;&#xB9C1;(Learning Rate Scheduling)</h4>
<p>YOLO&#xC758; &#xD559;&#xC2B5;&#xB960; &#xC2A4;&#xCF00;&#xC904;&#xB9C1;&#xC740; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC2B5;&#xB2C8;&#xB2E4;.   </p>
<blockquote>
<ol>
<li>&#xCCAB; epoch&#xC740; <code>learning rate = 10^-3 &#xC5D0;&#xC11C; 10^-2</code>&#xAE4C;&#xC9C0; &#xCC9C;&#xCC9C;&#xD788; &#xC62C;&#xB9BD;&#xB2C8;&#xB2E4;.<br>(&#xCC98;&#xC74C;&#xBD80;&#xD130; &#xB192;&#xC740; learning rate&#xB97C; &#xC8FC;&#xAC8C;&#xB418;&#xBA74; gradient&#xAC00; &#xBC1C;&#xC0B0;&#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;.)</li>
<li>&#xB2E4;&#xC74C; 75 epochs&#xC740; <code>learning rate = 10^-2</code> &#xC73C;&#xB85C; &#xD559;&#xC2B5;&#xC2DC;&#xD0B5;&#xB2C8;&#xB2E4;.</li>
<li>&#xB2E4;&#xC74C; 30 epochs&#xB294; <code>learning rate = 10^-3</code> &#xC73C;&#xB85C; &#xD559;&#xC2B5;&#xC2DC;&#xD0B5;&#xB2C8;&#xB2E4;.</li>
<li>&#xB2E4;&#xC74C; 30 epochs&#xB294; <code>learning rate = 10^-4</code> &#xC73C;&#xB85C; &#xD559;&#xC2B5;&#xC2DC;&#xD0B5;&#xB2C8;&#xB2E4;.</li>
</ol>
</blockquote>
<h4 id="020209-&#xC624;&#xBC84;&#xD53C;&#xD305;-&#xBC29;&#xC9C0;">02.02.09) &#xC624;&#xBC84;&#xD53C;&#xD305; &#xBC29;&#xC9C0;</h4>
<p>YOLO&#xC5D0;&#xC11C;&#xB294; &#xC624;&#xBC84;&#xD53C;&#xD305;&#xC744; &#xBC29;&#xC9C0;&#xD558;&#xAE30; &#xC704;&#xD574; dropout&#xACFC; data augmentation &#xAE30;&#xBC95;&#xC744; &#xC0AC;&#xC6A9;&#xD569;&#xB2C8;&#xB2E4;. dropout&#xC740; &#xCCAB; &#xBC88;&#xC9F8; fully connected layer&#xC5D0; &#xBD99;&#xC73C;&#xBA70; <code>dropout rate = 0.5</code>&#xB85C; &#xC124;&#xC815;&#xD588;&#xC2B5;&#xB2C8;&#xB2E4;. Data augmentation&#xC5D0;&#xB294; <code>scaling</code>, <code>translation</code>, <code>exposure</code>, <code>saturation</code>&#xC744; &#xC870;&#xC808;&#xD558;&#xB294; &#xBC29;&#xC2DD;&#xC73C;&#xB85C; &#xB2E4;&#xC591;&#xD558;&#xAC8C; &#xC9C4;&#xD589;&#xD558;&#xBA70;, <code>scaling</code>&#xACFC; <code>translation</code>&#xC740; &#xC6D0;&#xBCF8; &#xC774;&#xBBF8;&#xC9C0; &#xC0AC;&#xC774;&#xC988;&#xC758; 20%&#xAE4C;&#xC9C0; &#xC784;&#xC758;&#xB85C; &#xC870;&#xC808;&#xD558;&#xBA70;, <code>scaling</code>, <code>translation</code>&#xC740; HSV &#xACF5;&#xAC04;&#xC5D0;&#xC11C; 1.5&#xBC30;&#xAE4C;&#xC9C0; &#xC784;&#xC758;&#xB85C; &#xC870;&#xC808;&#xD569;&#xB2C8;&#xB2E4;.</p>
<h3 id="0203-&#xCD94;&#xB860;inference">02.03. &#xCD94;&#xB860;(Inference)</h3>
<p>&#xBAA8;&#xB378;&#xC740; &#xC774;&#xBBF8;&#xC9C0; &#xD55C;&#xC7A5; &#xB2F9; &#xCD1D; 98&#xAC1C;&#xC758; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xC608;&#xCE21;&#xD569;&#xB2C8;&#xB2E4;. &#xAC01; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xC5D0;&#xB294; &#xD074;&#xB798;&#xC2A4; &#xD655;&#xB960;&#xC774; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC785;&#xB825; &#xC774;&#xBBF8;&#xC9C0;&#xB97C; &#xB124;&#xD2B8;&#xC6CC;&#xD06C;&#xC5D0; &#xB2E8; &#xD55C;&#xBC88;&#xB9CC; &#xD1B5;&#xACFC;&#xC2DC;&#xD0A4;&#xBA74; &#xB418;&#xBBC0;&#xB85C; Test time&#xC2DC; YOLO&#xC758; &#xC18D;&#xB3C4;&#xB294; &#xC0C1;&#xB2F9;&#xD788; &#xBE60;&#xB985;&#xB2C8;&#xB2E4;. YOLO&#xACFC; &#xAC19;&#xC774; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC744; &#xC774;&#xC6A9;&#xD55C; &#xB514;&#xC790;&#xC778;&#xC73C;&#xB85C; &#xACAA;&#xC744; &#xC218; &#xC788;&#xB294; &#xBB38;&#xC81C;&#xC810; &#xD558;&#xB098;&#xAC00; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xADF8;&#xAC83;&#xC740; &#xBC14;&#xB85C; &#xD558;&#xB098;&#xC758; &#xAC1D;&#xCCB4;&#xB97C; &#xC5EC;&#xB7EC; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC774; &#xB3D9;&#xC2DC;&#xC5D0; &#xAC80;&#xCD9C;&#xD558;&#xB294; &#xACBD;&#xC6B0;&#xC785;&#xB2C8;&#xB2E4;. &#xD2B9;&#xD788; &#xAC1D;&#xCCB4;&#xAC00; &#xADF8;&#xB9AC;&#xB4DC;&#xC140;&#xB4E4;&#xC758; &#xACBD;&#xACC4;&#xC5D0; &#xC704;&#xCE58;&#xD558;&#xAC70;&#xB098; &#xC5EC;&#xB7EC; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xC744; &#xD3EC;&#xD568;&#xD560; &#xB9CC;&#xD07C; &#xD070; &#xAC1D;&#xCCB4;&#xC778; &#xACBD;&#xC6B0; &#xC774;&#xB7F0; &#xD604;&#xC0C1;&#xC774; &#xC790;&#xC8FC; &#xBC1C;&#xC0DD;&#xD569;&#xB2C8;&#xB2E4;. &#xBE44;&#xCD5C;&#xB300;&#xC5B5;&#xC81C;(Non-maximal suppression)&#xB294; &#xADF8;&#xB7EC;&#xD55C; &#xB2E4;&#xC911; &#xAC80;&#xCD9C; &#xBB38;&#xC81C;&#xB97C; &#xD574;&#xACB0;&#xD560; &#xC218; &#xC788;&#xB294; &#xC88B;&#xC740; &#xBC29;&#xBC95;&#xC785;&#xB2C8;&#xB2E4;. YOLO&#xB294; NMS&#xB97C; &#xD1B5;&#xD574; mAP&#xB97C; 2-3% &#xAC00;&#xB7C9; &#xC62C;&#xB9B4; &#xC218; &#xC788;&#xC5C8;&#xC2B5;&#xB2C8;&#xB2E4;.</p>
<h3 id="0204-yolo&#xC758;-&#xD55C;&#xACC4;">02.04. YOLO&#xC758; &#xD55C;&#xACC4;</h3>
<p>YOLO &#xBAA8;&#xB378;&#xC758; &#xD55C;&#xACC4;&#xC810;&#xB4E4;&#xC774; &#xBA87; &#xAC00;&#xC9C0; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC6B0;&#xC120; YOLO&#xB294; &#xAC01; &#xADF8;&#xB9AC;&#xB4DC; &#xC140;&#xB9C8;&#xB2E4; &#xC624;&#xC9C1; &#xD558;&#xB098;&#xC758; &#xAC1D;&#xCCB4;&#xB9CC;&#xC744; &#xAC80;&#xCD9C;&#xD560; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xC774;&#xB294; &#xAC1D;&#xCCB4; &#xAC80;&#xCD9C;&#xC5D0;&#xC11C; &#xC544;&#xC8FC; &#xAC15;&#xD55C; &#xACF5;&#xAC04;&#xC801; &#xC81C;&#xC57D;(spatial constraints)&#xC785;&#xB2C8;&#xB2E4;. &#xC774;&#xB7EC;&#xD55C; &#xACF5;&#xAC04;&#xC801; &#xC81C;&#xC57D;&#xC73C;&#xB85C; &#xC778;&#xD574; YOLO&#xB294; &apos;&#xC0C8; &#xB5BC;&apos;&#xC640; &#xAC19;&#xC774; &#xC791;&#xC740; &#xAC1D;&#xCCB4;&#xB4E4;&#xC774; &#xBB34;&#xB9AC;&#xC9C0;&#xC5B4; &#xC788;&#xB294; &#xACBD;&#xC6B0;&#xC758; &#xAC1D;&#xCCB4; &#xAC80;&#xCD9C;&#xC774; &#xC81C;&#xD55C;&#xC801;&#xC77C; &#xC218; &#xC788;&#xC2B5;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; &#xBC14;&#xC6B4;&#xB529; &#xBC15;&#xC2A4;&#xB97C; &#xB370;&#xC774;&#xD130;&#xB85C;&#xBD80;&#xD130; &#xD559;&#xC2B5;&#xD558;&#xAE30; &#xB54C;&#xBB38;&#xC5D0; &#xC77C;&#xBC18;&#xD654; &#xB2A5;&#xB825;&#xC774; &#xB5A8;&#xC5B4;&#xC9C0;&#xACE0;, &#xC774;&#xB85C; &#xC778;&#xD574; train time&#xC5D0; &#xBCF4;&#xC9C0; &#xBABB;&#xD588;&#xB358; &#xC885;&#xD6A1;&#xBE44;&#xC758; &#xAC1D;&#xCCB4;&#xB97C; &#xC798; &#xAC80;&#xCD9C;&#xD558;&#xC9C0; &#xBABB;&#xD569;&#xB2C8;&#xB2E4;. &#xADF8;&#xB9AC;&#xACE0; &#xB9C8;&#xC9C0;&#xB9C9;&#xC73C;&#xB85C; YOLO&#xC5D0;&#xC11C; &#xAC00;&#xC7A5; &#xBB38;&#xC81C;&#xAC00; &#xB418;&#xB294; &#xBD80;&#xBD84;&#xC774; &#xBC14;&#xB85C; &#xC798;&#xBABB;&#xB41C; localizations &#xC785;&#xB2C8;&#xB2E4;.</p>
<h2 id="04-experiments">04. Experiments</h2>
<h3 id="0401-comparison-to-other-real-time-systems">04.01. Comparison to Other Real-Time Systems</h3>
<p>DPM 100Hz/30Hz &#xAD6C;&#xD604;&#xCCB4;&#xC640; GPU &#xBC84;&#xC804;&#xC758; YOLO&#xB97C; &#xAE30;&#xC900;&#xC73C;&#xB85C; &#xBAA8;&#xB378;&#xC744; YOLO &#xB0B4;&#xC758; &#xBCC0;&#xD615; &#xBAA8;&#xB378;&#xC758; &#xC131;&#xB2A5; &#xBE44;&#xAD50;&#xB97C; &#xD569;&#xB2C8;&#xB2E4;.</p>
<h4 id="fast-yolo">Fast YOLO</h4>
<ul>
<li>PASCAL VOC&#xAE30;&#xC900; &#xAC00;&#xC7A5; &#xBE60;&#xB978; Object Detection &#xC54C;&#xACE0;&#xB9AC;&#xC998;</li>
<li>52.7% mAP (100Hz/30Hz DPM &#xAE30;&#xC900; 2&#xBC30; &#xC774;&#xC0C1; &#xD5A5;&#xC0C1;)</li>
</ul>
<h4 id="yolo">YOLO</h4>
<ul>
<li>&#xC2E4;&#xC2DC;&#xAC04; &#xC131;&#xB2A5;&#xC744; &#xB9CC;&#xC871;&#xD558;&#xBA74;&#xC11C; mAP&#xB294; 63.4%</li>
<li>VGG-16&#xC744; feature extractor&#xB85C; &#xC0AC;&#xC6A9;&#xD55C; &#xACBD;&#xC6B0;&#xC5D0;&#xB294; &#xC131;&#xB2A5;&#xC774; &#xC99D;&#xAC00;&#xD558;&#xB098;, &#xC18D;&#xB3C4; &#xAC10;&#xC18C;</li>
</ul>
<h4 id="fastest-dpm"><a href="http://www.cbsr.ia.ac.cn/users/jjyan/Fastest_DPM.pdf" target="_blank">Fastest DPM</a></h4>
<ul>
<li><p>&#xC57D;&#xAC04;&#xC758; mAP &#xC131;&#xB2A5;&#xD558;&#xB77D;&#xC73C;&#xB85C; Detection &#xC18D;&#xB3C4;&#xB97C; &#xB192;&#xC778; &#xBAA8;&#xB378;</p>
<p>&#xD558;&#xC9C0;&#xB9CC; &#xC2E4;&#xC2DC;&#xAC04; detection system&#xC774;&#xB77C;&#xACE0; &#xBD80;&#xB974;&#xAE30;&#xC5D4; &#xC18D;&#xB3C4;&#xAC00; &#xB290;&#xB9BC;</p>
</li>
<li><p>30.7% mAP&#xB85C; &#xC131;&#xB2A5; &#xBC0F; &#xC18D;&#xB3C4;&#xCE21;&#xBA74;&#xC5D0;&#xC11C; YOLO &#xB300;&#xBE44; &#xC804;&#xBC18;&#xC801;&#xC73C;&#xB85C; &#xC548;&#xC88B;&#xC74C;</p>
</li>
</ul>
<h4 id="r-cnn-&#xACC4;&#xC5F4;">R-CNN &#xACC4;&#xC5F4;</h4>
<p>&#xCD5C;&#xADFC; <a href="https://arxiv.org/pdf/1311.2524.pdf" target="_blank">R-CNN</a>&#xACC4;&#xC5F4;&#xC5D0;&#xC11C; &#xC18D;&#xB3C4;&#xAC00; &#xAC1C;&#xC120;&#xB41C; <a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank">Fast R-CNN</a>&#xC774; &#xB098;&#xC654;&#xC73C;&#xB098;, &#xC18D;&#xB3C4; &#xCE21;&#xBA74;&#xC5D0;&#xC11C; &#xC2E4;&#xC2DC;&#xAC04; &#xC131;&#xB2A5;&#xC5D0;&#xB294; &#xD55C;&#xCC38; &#xBABB;&#xBBF8;&#xCE58;&#xB294; &#xC131;&#xB2A5;&#xC744; &#xAC16;&#xC74C;</p>
<ul>
<li><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank">Fast R-CNN</a> : 70% mAP, 0.5 fps</li>
<li><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank">Fast R-CNN</a> with VGG-16 : 73.2% mAP, 7 fps</li>
</ul>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49447560-33669880-f81a-11e8-9a2f-db7588e8357b.png" alt="benchmark_with_other_systems"></p>
<p>&#x200B;    </p>
<h3 id="0402-voc-2007-error-analysis">04.02. VOC 2007 Error Analysis</h3>
<p>VOC 2007 Dataset&#xC5D0;&#xC11C; YOLO, <a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank">Fast R-CNN</a> &#xBAA8;&#xB378;&#xC758; &#xC5D0;&#xB7EC;&#xBD84;&#xC11D;&#xC744; &#xD558;&#xAE30; &#xC704;&#xD558;&#xC5EC; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC740; &#xB808;&#xD37C;&#xB7F0;&#xC2A4; <a href="http://dhoiem.web.engr.illinois.edu/publications/eccv2012_detanalysis_derek.pdf" target="_blank">Diagnosing Error in Object Detectors</a> &#xB97C; &#xCC38;&#xACE0;&#xD558;&#xC5EC; &#xAE30;&#xC900;&#xC744; &#xC7A1;&#xC74C;</p>
<ul>
<li>Correct : class&#xAC00; &#xC815;&#xD655;&#xD558;&#xBA70; IOU&#xAC00; 0.5&#xBCF4;&#xB2E4; &#xD070; &#xACBD;&#xC6B0;</li>
<li>Localization : class&#xAC00; &#xC815;&#xD655;&#xD558;&#xACE0;, IOU&#xAC00; 0.1&#xBCF4;&#xB2E4; &#xD06C;&#xACE0; 0.5&#xBCF4;&#xB2E4; &#xC791;&#xC740; &#xACBD;&#xC6B0;</li>
<li>Similar : class&#xAC00; &#xC720;&#xC0AC;&#xD558;&#xACE0; IOU&#xAC00; 0.1&#xBCF4;&#xB2E4; &#xD070; &#xACBD;&#xC6B0;</li>
<li>Other : class&#xB294; &#xD2C0;&#xB838;&#xC73C;&#xB098;, IOU&#xAC00; 0.1&#xBCF4;&#xB2E4; &#xD070; &#xACBD;&#xC6B0;</li>
<li>Background : &#xC5B4;&#xB5A4; Object&#xC774;&#xB358;&#xAC04;&#xC5D0; IOU&#xAC00; 0.1&#xBCF4;&#xB2E4; &#xC791;&#xC740; &#xACBD;&#xC6B0;</li>
</ul>
<p>&#xBD84;&#xC11D; &#xACB0;&#xACFC;&#xB294; &#xB2E4;&#xC74C;&#xACFC; &#xAC19;&#xC74C;</p>
<ul>
<li>YOLO&#xB294; localize &#xC5D0;&#xB7EC;&#xAC00; &#xC2EC;&#xD568;</li>
<li><a href="https://arxiv.org/pdf/1506.01497.pdf" target="_blank">Fast R-CNN</a>&#xC740; &#xC0C1;&#xB300;&#xC801;&#xC73C;&#xB85C; localization &#xC5D0;&#xB7EC;&#xB294; &#xC801;&#xC73C;&#xB098; background &#xC5D0;&#xB7EC;&#xAC00; &#xD07C;.</li>
</ul>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49448061-64939880-f81b-11e8-85d8-7bfea72dae47.png" alt="error_analysis"></p>
<p>&#x200B;    </p>
<h3 id="0404-voc-2012-result">04.04. VOC 2012 Result</h3>
<p>VOC 2012 &#xACB0;&#xACFC;&#xC5D0;&#xC11C; YOLO&#xB294; 57.9% mAP&#xB97C; &#xB2EC;&#xC131;&#xD568;</p>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49448183-af151500-f81b-11e8-8c2f-a3eefaf96f24.png" alt="pascal_voc2012_leaderboard"></p>
<p>&#x200B;    </p>
<h3 id="0405-generalizability-person-detection-in-artwork">04.05. Generalizability: Person Detection in Artwork</h3>
<p><a href="https://people.eecs.berkeley.edu/~shiry/publications/Picasso_ECCV_2014.pdf" target="_blank">Picasso Dataset</a> &#xC640; <a href="https://core.ac.uk/download/pdf/38151134.pdf" target="_blank">People-Art Dataset</a>&#xB97C; &#xC774;&#xC6A9;&#xD558;&#xC5EC; YOLO&#xC640; &#xB2E4;&#xB978; Detection System&#xB4E4;&#xC758; &#xC131;&#xB2A5;&#xC744; &#xBE44;&#xAD50;&#xD568;</p>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49448429-3bbfd300-f81c-11e8-9e87-ad2ef8923977.png" alt="generalization_result"></p>
<p>&#x200B;    </p>
<h2 id="05-qualitative-result">05. Qualitative Result</h2>
<p>&#xC544;&#xB798; &#xC0AC;&#xC9C4;&#xC740; YOLO&#xC758; Object Detection &#xACB0;&#xACFC;&#xC785;&#xB2C8;&#xB2E4;.</p>
<p>&#x200B;    </p>
<p><img src="https://user-images.githubusercontent.com/13328380/49448530-70338f00-f81c-11e8-9bcc-0842659bc1c0.png" alt="qualitative_result"></p>
<p>&#x200B;    </p>
<h2 id="reference">Reference</h2>
<p>&#xC544;&#xB798; &#xC790;&#xB8CC;&#xB4E4;&#xC740; &#xBCF8; &#xBB38;&#xC11C;&#xC640; &#xD568;&#xAED8; &#xBCF4;&#xC2DC;&#xBA74; YOLO&#xB97C; &#xC774;&#xD574;&#xD558;&#xB294;&#xB370; &#xB3C4;&#xC6C0;&#xC774; &#xB420; &#xC218; &#xC788;&#xB294; &#xC790;&#xB8CC; &#xBAA8;&#xC74C;&#xC785;&#xB2C8;&#xB2E4;.</p>
<h4 id="1-cvpr---you-only-look-once-unified-real-time-object-detection">1). CVPR - You Only Look Once: Unified, Real-Time Object Detection</h4>
<p><a href="https://www.youtube.com/watch?v=NM6lrxy0bxs" target="_blank"><img src="https://img.youtube.com/vi/NM6lrxy0bxs/0.jpg" alt="You Only Look Once: Unified, Real-Time Object Detection)"></a></p>
<h4 id="2-you-only-look-once">2). You Only Look Once</h4>
<p><a href="https://www.youtube.com/watch?v=L0tzmv--CGY" target="_blank"><img src="https://img.youtube.com/vi/L0tzmv--CGY/0.jpg" alt="YOLO: You only look once (How it works)"></a></p>
<h4 id="3-pr-016-you-only-look-once">3). PR-016: You only look once</h4>
<p><a href="https://www.youtube.com/watch?v=eTDcoeqj1_w" target="_blank"><img src="https://img.youtube.com/vi/eTDcoeqj1_w/0.jpg" alt="PR-016: You only look once: Unified, real-time object detection"></a></p>
<ul>
<li><a href="https://curt-park.github.io/2017-03-26/yolo/" target="_blank">Curt-Park - [&#xBD84;&#xC11D;] YOLO</a></li>
<li><a href="https://jamiekang.github.io/2017/06/18/you-only-look-once-unified-real-time-object-detection/" target="_blank">Jamie Kang&apos;s - You Only Look Once : Unified, Real-Time Object Detection</a></li>
<li><a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;ved=2ahUKEwiozv-VtobfAhXDdN4KHRFND4AQFjAEegQIAxAC&amp;url=http%3A%2F%2Fwww.modulabs.co.kr%2F%3Fmodule%3Dfile%26act%3DprocFileDownload%26file_srl%3D20615%26sid%3D8629ec2e16ef451a8ce8ad206b112b42%26module_srl%3D18164&amp;usg=AOvVaw0IGwOXa1Er1GIlNH7o0DVi" target="_blank">&#xBAA8;&#xB450;&#xC758; &#xC5F0;&#xAD6C;&#xC18C; - YOLO &#xB17C;&#xBB38;&#xC694;&#xC57D;</a></li>
<li><a href="http://blog.naver.com/PostView.nhn?blogId=sogangori&amp;logNo=220993971883&amp;parentCategoryNo=15&amp;categoryNo=&amp;viewDate=&amp;isShowPopularPosts=true&amp;from=search" target="_blank">sogangori - YOLO, Object Detection Network</a></li>
<li><a href="http://arclab.tistory.com/167" target="_blank">Arc Lab - [&#xB17C;&#xBB38; &#xC694;&#xC57D; 12] You Only Look Once: Unified, Real-Time Object Detection</a></li>
<li><a href="http://wewinserv.tistory.com/79" target="_blank">Wonju Seo - You Only Look Once : Unified Real-Time Object Detection</a></li>
</ul>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.html" class="navigation navigation-prev " aria-label="Previous page: 04. You Only Look Once: Unified, Real-Time Object Detection">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="04_02_Model.html" class="navigation navigation-next " aria-label="Next page: 02). Model">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"01). You Only Look Once 논문리뷰","level":"1.1.5.1","depth":3,"next":{"title":"02). Model","level":"1.1.5.2","depth":3,"path":"posts/04_02_Model.md","ref":"posts/04_02_Model.md","articles":[]},"previous":{"title":"04. You Only Look Once: Unified, Real-Time Object Detection","level":"1.1.5","depth":2,"path":"posts/04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.md","ref":"posts/04_00_You_Only_Look_Once_Unified_Real_Time_Object_Detection.md","articles":[{"title":"01). You Only Look Once 논문리뷰","level":"1.1.5.1","depth":3,"path":"posts/04_01_Review_of_YOLO_Paper.md","ref":"posts/04_01_Review_of_YOLO_Paper.md","articles":[]},{"title":"02). Model","level":"1.1.5.2","depth":3,"path":"posts/04_02_Model.md","ref":"posts/04_02_Model.md","articles":[]}]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"posts/04_01_Review_of_YOLO_Paper.md","mtime":"2018-12-14T06:10:32.011Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2018-12-14T06:19:16.695Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

